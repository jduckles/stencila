# Stencila Prompts

**Prompts for generative AI specialized for scientific research, coding and writing**

## ü§ñ Introduction

Custom prompts are an effective way to improve the performance of large language models and other generative AI on specific tasks in specific contexts.

There are two types of prompts in this module:

- [`builtin`](builtin): prompts that are embedded into the `stencila` CLI binary to be used by builtin prompts

- [`contrib`](contrib): contributed prompts that are not builtin but which can be fetched from this repo (ü¶Ñ this functionality does not yet exist!)

## ‚úèÔ∏è Format

Prompts are specified in Markdown files with a YAML header (surrounded by three dashes i.e. `---`), the system prompt, a thematic break (another set of three dashes), and the user prompt. i.e.

```markdown
---
name: example/prompt
description: An example prompt

models:
  - openai/gpt-3.5-turbo-1106
  - anthropic/claude-2.1
---

The system prompt

---

The user prompt
```

### Header

#### Required fields

The following fields are required in the header:

- `name`: A unique name for the prompt
- `description`: A description of what the prompt does and how it does it
- `models`: A list of general prompts that will be delegated to; delegation will be attempted in the order specified

#### Instruction matching

Several header fields affect the which instructions an prompt will execute on:

- `preference-rank`: The relative rank of the preference for the prompt (0-256). Prompts with a higher rank will be checked for an instruction match before those with a lower rank.

- `instruction-type`: The type of instruction and whether or not it has `content`

  - `insert-blocks`: An [`InstructionBlock`](https://github.com/stencila/stencila/blob/main/docs/reference/schema/edits/instruction-block.md) with no `content`
  - `modify-blocks`: An `InstructionBlock` with some `content`
  - `insert-inlines`: An [`InstructionInline`](https://github.com/stencila/stencila/blob/main/docs/reference/schema/edits/instruction-inline.md) with no `content`
  - `modify-inlines`: An `InstructionInline` with some `content`

- `instruction-regexes`: A list of regular expressions to apply to the text of the instruction. At least one of these should match.

If the instruction has any `content`, then the following matching options will also apply:

- `content-nodes`: A regular expression to apply to a comma separated list of the types of nodes in the content. e.g. `^CodeChunk$` means only one `CodeChunk` node.

- `content-regexes`: A list of regular expressions to apply to the text of the content. At least one of these should match.

#### Prompt context

These fields affect the variables that are available within the user prompt template.

- `document-format <DOCUMENT_FORMAT>`: The format to convert the document content into before the user prompt is rendered. Default value: `html`
- `content-format <CONTENT_FORMAT>`: The format to convert the instruction content (if any) into before the user prompt is rendered. Default value: `html`

#### Response parsing, assertions and retries

> [!WARNING]
> None of the the functionality described in this section is implemented yet

For text-to-text models, Stencila parses the content generated by the LLM into an array of nodes (specifically blocks for an `InstructionBlock` and inlines for an `InstructionInline`). To enable this the format of the generated context should be specified:

- `generated-format`: The format of the generated content. Default value: `html`

The nodes parsed from the generated content can then have assertions applied to them to ensure that they are of the expected type:

- `assert-nodes`: Assert that the types of nodes that are generated match this regex pattern e.g `(Paragraph,?)+` = one or more paragraphs
- `assert-syntax`: Assert that the node's `code` is syntactically valid for the `programmingLanguage` specified (for nodes having both properties)
- `assert-deps`: If the node is derived from [`CodeExecutable`](https://github.com/stencila/stencila/blob/main/docs/reference/schema/code/code-executable.md), assert that dependencies in the code are available in the document's execution context

If any of the assertions above fail a retry will be attempted. The maximum number of retries can be configured:

- `max-retries`: The maximum number of retries for generating valid nodes Default value: `1`

#### LLM parameters

These parameters can be specified in the prompt header and will be passed on to the LLM via it's API:

- `mirostat`: Enable Mirostat sampling for controlling perplexity
- `mirostat-eta`: Influences how quickly the algorithm responds to feedback from the generated text
- `mirostat-tau`: Controls the balance between coherence and diversity of the output
- `num-ctx`: Sets the size of the context window used to generate the next token
- `num-gqa`: The number of GQA groups in the transformer layer
- `num-gpu`: The number of layers to send to the GPU(s)
- `num-thread`: Sets the number of threads to use during computation
- `repeat-last-n`: Sets how far back for the model to look back to prevent repetition
- `repeat-penalty`: Sets how strongly to penalize repetitions
- `temperature`: The temperature of the model
- `seed`: Sets the random number seed to use for generation
- `stop`: Sets the stop sequences to use
- `max-token`: The maximum number of tokens to generate
- `tfs-z`: Tail free sampling is used to reduce the impact of less probable tokens from the output
- `num-predict`: Maximum number of tokens to predict when generating text
- `top-k`: Reduces the probability of generating nonsense
- `top-p`: Works together with top-k
- `image-quality`: The quality of the image that will be generated
- `image-style`: The style of the generated images. Must be one of `vivid` or `natural`. Vivid causes the model to lean towards generating hyper-real and dramatic images. Natural causes the model to produce more natural, less hyper-real looking images. Supported by `openai/dall-e-3`

### Prompts

The user prompt in the prompt Markdown file is a Jinja template so you can use [this syntax](https://docs.rs/minijinja/latest/minijinja/syntax/index.html) to alter the prompt based on the context of the instruction. e.g.

```markdown
You will be provided with several fragments of text, each within an XML <fragment> tag. Summarize the fragments as accurately as possible in the style provided in the XML <style> tag. Use no more than 4 sentences.

---

<style>{{ instruction_text }}</style>

{% for fragment in fragments %}
<fragment>{{ fragment }}</fragment>
{% endfor %}
```

## üõ†Ô∏è Development

There are some tools in Stencila for helping with [prompt engineering](https://en.wikipedia.org/wiki/Prompt_engineering): improving the performance of prompts used by prompts for a specific task.

### Listing

The `stencila prompts` command (‚ö†Ô∏è this is planned to be renamed to `stencila ai prompts` soon) provides a list of the available prompts. If the relevant API key is not set in an environment variable, the corresponding prompts will not appear in this list.

### Testing

The `stencila test` command (‚ö†Ô∏è will be renamed to `stencila ai test`) can be used to run prompts on the test instructions in the [`tests`](tests) folder.

Each test folder has a `document.md`, an example document written in Markdown, and one or more instructions written in YAML files. You can run each test instruction individually, e.g.

```console
cd examples/instructions
cargo run -p cli test doctor-who create-summary --reps 3
```

The `test` command will create a Markdown file with the same name as the instruction (in this case `create-summary.md`) with a header detailing the task created from the instruction and the document and the content generated for each repetition.

### REPL

The `stencila repl` command (‚ö†Ô∏è will be renamed to `stencila ai repl`) provides a read-evaluate-print-loop for engineering prompts. When the CLI is compiled in debug mode, prompts will be reloaded from disk each time they are used.

This means that you can alter the prompt during a REPL session and check how it affects performance. The REPL has up and down arrow history support so you can easily repeat the same instructions after modifying the prompt.

#### Options

Options such as the prompt can be set at the start of a session e.g.

```console
cargo run -p cli repl --prompt stencila/insert-blocks
```

or during the session:

```
>> --prompt stencila/modify-inlines
Options were updated
>> ?options
{"prompt":"stencila/modify-inlines"}
```

For a full list of options use `--help`. You can set any of the options this way. For example, setting the temperature of the model:

```
>> --temperature 0.2
Options were updated
>> ?options
{"prompt":"stencila/modify-inlines","temperature":0.2}
```

#### Recording

At session start up, you can specify the `--record` flag to make the REPL ask you whether you want to store the trial (the prompt, prompt, instruction, response, options used etc) in a local SQLite database:

```sh
$ touch testing.sqlite3 # In the future this should not be necessary
$ cargo run -p cli repl --record
```

```
>> create a 3x5 table with animal names as column headers
custom/insert-block

| Animal 1 | Animal 2 | Animal 3 | Animal 4 | Animal 5 |
|----------|----------|----------|----------|----------|
|          |          |          |          |          |
|          |          |          |          |          |
|          |          |          |          |          |
>> Would you like to record this trial? (y/n)
>> y
>> create a 3x5 table with specific animal names as column headers
custom/insert-block

| Lion | Tiger | Elephant | Giraffe | Zebra |
|------|-------|----------|---------|-------|
|      |       |          |         |       |
|      |       |          |         |       |
|      |       |          |         |       |
>> Would you like to record this trial? (y/n)
>>
```
